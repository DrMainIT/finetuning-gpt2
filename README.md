# finetuning-gpt2

This repository contains the code for fine-tuning the GPT-2-mini language model for text generation tasks. The code is fine-tuned on sentiment analysis task using the mteb dataset. The model is fine-tuned using the Hugging Face Transformers library. The fine-tuned model is then used to recognise tweet for sentiment analysis.